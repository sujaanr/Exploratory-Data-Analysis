# -*- coding: utf-8 -*-
"""INF2178A1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nMkDhEvQ2A9BmzyEqQjQrKtBfBGqfoyH

# Preparing Dataset
"""

# Commented out IPython magic to ensure Python compatibility.
# INF2178 Assignment 1

# Library imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
import statsmodels.api as sm
from statsmodels.formula.api import ols
# %pip install bioinfokit
from bioinfokit.analys import stat

# Read input file
file_path = '/content/INF2178_A2_data.xlsx'
df = pd.read_excel(file_path)

# Create an output file
import matplotlib.backends.backend_pdf as pdf_backend
pdf_filename = 'output_report.pdf'
pdf_pages = pdf_backend.PdfPages(pdf_filename)

# Display information on dataset
print(df.info())

# Display initial rows of dataset
print(df.head(10))

# Reshape the dataframe suitable for statsmodels package
df_melt = pd.melt(df.reset_index(), id_vars=['_id'], value_vars=['IGSPACE', 'TGSPACE', 'PGSPACE', 'KGSPACE', 'SGSPACE'])

# Replace column names
df_melt.columns = ['_id', 'treatments', 'value']

# Generate a boxplot to see the data distribution by treatments
ax = sns.boxplot(x='treatments', y='value', data=df_melt, color='#99c2a2')
ax = sns.swarmplot(x='treatments', y='value', data=df_melt, color='#7d0013')
plt.show()

# Ordinary Least Squares (OLS) model
model = ols('value ~ C(treatments)', data=df_melt).fit()
anova_table = sm.stats.anova_lm(model, typ=2)
print(anova_table)

# Post hoc test using Tukey's HSD
from statsmodels.stats.multicomp import pairwise_tukeyhsd

tukey = pairwise_tukeyhsd(endog=df_melt['value'], groups=df_melt['treatments'], alpha=0.05)
print(tukey.summary())

# Checking model diagnostics
# Assumption 1: Residuals are normally distributed
sm.qqplot(model.resid, line='45')
plt.xlabel("Theoretical Quantiles")
plt.ylabel("Standardized Residuals")
plt.show()

# Histogram of Residuals
plt.hist(model.resid, bins='auto', histtype='bar', ec='k')
plt.xlabel("Residuals")
plt.ylabel('Frequency')
plt.show()

# Assumption 1: Residuals are normally distributed (Shapiro-Wilk test)
w, pvalue_shapiro = stats.shapiro(model.resid)
print(f"Shapiro-Wilk Test - p-value: {pvalue_shapiro}")

# Assumption 2: Variances are homogeneous (Bartlett's test)
bartlett_stat, pvalue_bartlett = stats.bartlett(*[group[1] for group in df.groupby('AUSPICE')['TOTSPACE']])
print(f"Bartlett's Test - p-value: {pvalue_bartlett}")

# Assumption 2: Variances are homogeneous (Levene's test)
levene_stat, pvalue_levene = stats.levene(*[group[1] for group in df.groupby('AUSPICE')['TOTSPACE']])
print(f"Levene's Test - p-value: {pvalue_levene}")

"""# Summary Statistics"""

# Function for summary statistics
def get_summary_statistics(dataset, label='Dataset'):

    mean = np.round(np.mean(dataset), 2)
    median = np.round(np.median(dataset), 2)
    min_value = np.round(dataset.min(), 2)
    max_value = np.round(dataset.max(), 2)
    quartile_1 = np.round(dataset.quantile(0.25), 2)
    quartile_3 = np.round(dataset.quantile(0.75), 2)

    # Interquartile range
    iqr = np.round(quartile_3 - quartile_1, 2)

    print(f'{label} Summary Statistics:')
    print('Min: %s' % min_value)
    print('Mean: %s' % mean)
    print('Max: %s' % max_value)
    print('25th percentile: %s' % quartile_1)
    print('Median: %s' % median)
    print('75th percentile: %s' % quartile_3)
    print('Interquartile range (IQR): %s' % iqr)
    print('\n\n')

# Select relevant data columns
selected_data.dtypes

# Fill missing values with the mean of the column
selected_data.select_dtypes(include='object')

selected_data['incorrect_column'] = selected_data['incorrect_column'].astype(float)

# Display summary statistics for relevant columns
get_summary_statistics(selected_data)

# Display summary statistics for relevant columns
get_summary_statistics(selected_data['SERVICE_USER_COUNT'], label='Service User Count')
get_summary_statistics(selected_data['CAPACITY_ACTUAL_BED'], label='Capacity Actual Bed')
get_summary_statistics(selected_data['OCCUPIED_BEDS'], label='Occupied Beds')
get_summary_statistics(selected_data['CAPACITY_ACTUAL_ROOM'], label='Capacity Actual Room')
get_summary_statistics(selected_data['OCCUPIED_ROOMS'], label='Occupied Rooms')
get_summary_statistics(selected_data['OCCUPANCY_RATE_BEDS'], label='Occupancy Rate for Beds')
get_summary_statistics(selected_data['OCCUPANCY_RATE_ROOMS'], label='Occupancy Rate for Rooms')

"""# Quantitative analysis using t-tests"""

# Two sample t-test
from scipy import stats

# Separate data based on program models
emergency_data = df[df['PROGRAM_MODEL'] == 'Emergency']
transitional_data = df[df['PROGRAM_MODEL'] == 'Transitional']

# Calculate means for OCCUPANCY_RATE_BEDS
mean_emergency_beds = emergency_data['OCCUPANCY_RATE_BEDS'].mean()
mean_transitional_beds = transitional_data['OCCUPANCY_RATE_BEDS'].mean()

# Calculate means for OCCUPANCY_RATE_ROOMS
mean_emergency_rooms = emergency_data['OCCUPANCY_RATE_ROOMS'].mean()
mean_transitional_rooms = transitional_data['OCCUPANCY_RATE_ROOMS'].mean()

# Print means
print(f"Mean Occupancy Rates (Beds) for Emergency: {mean_emergency_beds:.2f}")
print(f"Mean Occupancy Rates (Beds) for Transitional: {mean_transitional_beds:.2f}")
print(f"Mean Occupancy Rates (Rooms) for Emergency: {mean_emergency_rooms:.2f}")
print(f"Mean Occupancy Rates (Rooms) for Transitional: {mean_transitional_rooms:.2f}")

# Perform t-test for OCCUPANCY_RATE_BEDS
t_stat_bed, p_value_bed = ttest_ind(emergency_data['OCCUPANCY_RATE_BEDS'].dropna(), transitional_data['OCCUPANCY_RATE_BEDS'].dropna(), equal_var=False)

# Perform t-test for OCCUPANCY_RATE_ROOMS
t_stat_room, p_value_room = ttest_ind(emergency_data['OCCUPANCY_RATE_ROOMS'].dropna(), transitional_data['OCCUPANCY_RATE_ROOMS'].dropna(), equal_var=False)

# Print t-test results for OCCUPANCY_RATE_BEDS
print(f"\nT-statistic for Occupancy Rates (Beds): {t_stat_bed}")
print(f"P-value for Occupancy Rates (Beds): {p_value_bed}")

# Print t-test results for OCCUPANCY_RATE_ROOMS
print(f"T-statistic for Occupancy Rates (Rooms): {t_stat_room}")
print(f"P-value for Occupancy Rates (Rooms): {p_value_room}")

# Interpret the results
alpha = 0.05
if p_value_bed < alpha:
    print("\nReject the null hypothesis for Occupancy Rates (Beds). There is a significant difference between program models.")
else:
    print("\nFail to reject the null hypothesis for Occupancy Rates (Beds). There is no significant difference between program models.")

if p_value_room < alpha:
    print("Reject the null hypothesis for Occupancy Rates (Rooms). There is a significant difference between program models.")
else:
    print("Fail to reject the null hypothesis for Occupancy Rates (Rooms). There is no significant difference between program models.")

# Welch's t-test
x = emergency_data['OCCUPANCY_RATE_BEDS'].dropna()
y = transitional_data['OCCUPANCY_RATE_BEDS'].dropna()

# Using SciPy Package for Welch's t-test
t_stat, p_val = stats.ttest_ind(x, y, equal_var=False)
print("Welch's t-statistic =", t_stat)
print("p-value =", p_val)

# Two sample t-test
# Calculate mean service user count for 'Emergency' program model
mean_service_user_count_emergency = emergency_data['SERVICE_USER_COUNT'].mean()
print(f"Mean Service User Count (Emergency): {mean_service_user_count_emergency:.2f}")

# Calculate mean service user count for 'Transitional' program model
mean_service_user_count_transitional = transitional_data['SERVICE_USER_COUNT'].mean()
print(f"Mean Service User Count (Transitional): {mean_service_user_count_transitional:.2f}")

# Perform two-sample t-test for SERVICE_USER_COUNT between 'Emergency' and 'Transitional' program models
t_stat_service_user_count, p_value_service_user_count = ttest_ind(emergency_data['SERVICE_USER_COUNT'].dropna(), transitional_data['SERVICE_USER_COUNT'].dropna(), equal_var=False)

# Print the results for SERVICE_USER_COUNT between 'Emergency' and 'Transitional' program models
print(f"\nT-statistic for Service User Count: {t_stat_service_user_count}")
print(f"P-value for Service User Count: {p_value_service_user_count}")

# Interpret the result for SERVICE_USER_COUNT between 'Emergency' and 'Transitional' program models
alpha = 0.05
if p_value_service_user_count < alpha:
    print("Reject the null hypothesis. There is a significant difference in the mean of SERVICE_USER_COUNT between 'Emergency' and 'Transitional' program models.")
else:
    print("Fail to reject the null hypothesis. There is no significant difference in the mean of SERVICE_USER_COUNT between 'Emergency' and 'Transitional' program models.")

"""# Exploratory Data Analysis (EDA)"""

# Exploratory Data Analysis (EDA)

# Scatter Plot of Actual Capacity vs Occupied Beds
plt.figure(figsize=(9, 6))
sns.scatterplot(x='CAPACITY_ACTUAL_BED', y='OCCUPIED_BEDS', data=df)
plt.title('Scatter Plot of Actual Capacity of Beds vs Occupied Beds')
plt.xlabel('Actual Capacity of Beds')
plt.ylabel('Occupied Beds')
pdf_pages.savefig()
plt.show()

# Boxplot for Program Model analysis
plt.figure(figsize=(12, 6))
sns.boxplot(x='PROGRAM_MODEL', y='OCCUPIED_BEDS', data=df)
plt.title('Occupancy Rates by Program Model')
plt.xlabel('Program Model')
plt.ylabel('Occupied Beds')
plt.xticks(rotation=45)
pdf_pages.savefig()
plt.show()

# Histogram for Service User Count distribution
plt.figure(figsize=(8, 6))
sns.histplot(df['SERVICE_USER_COUNT'], bins=20, kde=True)
plt.title('Distribution of Service User Count')
plt.xlabel('Service User Count')
plt.ylabel('Frequency')
pdf_pages.savefig()
plt.show()

# Temporal Analysis
df['OCCUPANCY_DATE'] = pd.to_datetime(df['OCCUPANCY_DATE'])

# Line Plot for temporal analysis
plt.figure(figsize=(12, 6))
sns.lineplot(x='OCCUPANCY_DATE', y='OCCUPIED_BEDS', data=df, ci=None)
plt.title('Temporal Analysis of Occupied Beds Over 2021')
plt.xlabel('Date')
plt.ylabel('Occupied Beds')
pdf_pages.savefig()
plt.show()

# Boxplot for Sector analysis
plt.figure(figsize=(12, 6))
sns.boxplot(x='SECTOR', y='OCCUPIED_BEDS', data=df)
plt.title('Occupancy Rates by Sector')
plt.xlabel('Sector')
plt.ylabel('Occupied Beds')
pdf_pages.savefig()
plt.show()

# Boxplot for Overnight Service Type analysis
plt.figure(figsize=(12, 6))
sns.boxplot(x='OVERNIGHT_SERVICE_TYPE', y='SERVICE_USER_COUNT', data=df)
plt.title('Occupancy Rates by Overnight Service Type')
plt.xlabel('Overnight Service Type')
plt.ylabel('Service User Count')
plt.xticks(rotation=45)
pdf_pages.savefig()
plt.show()

# Boxplot for Capacity Type analysis
plt.figure(figsize=(12, 6))
sns.boxplot(x='CAPACITY_TYPE', y='SERVICE_USER_COUNT', data=df)
plt.title('Occupancy Rates Based on Capacity Type')
plt.xlabel('Capacity Type')
plt.ylabel('Service User Count')
pdf_pages.savefig()
plt.show()

# Boxplot for Program Model analysis (Beds)
plt.figure(figsize=(12, 8))
sns.boxplot(x='PROGRAM_MODEL', y='OCCUPANCY_RATE_BEDS', data=selected_data)
plt.title('Occupancy Rates by Program Model (Beds)')
plt.xlabel('Program Model')
plt.ylabel('Occupancy Rate (Beds)')
pdf_pages.savefig()
plt.show()

# Violinplot for Occupancy Rate distribution (Beds)
plt.figure(figsize=(12, 8))
sns.violinplot(x='PROGRAM_MODEL', y='OCCUPANCY_RATE_BEDS', data=selected_data)
plt.title('Occupancy Rates Distribution by Program Model (Beds)')
plt.xlabel('Program Model')
plt.ylabel('Occupancy Rate (Beds)')
pdf_pages.savefig()
plt.show()

# Violionplot for Occupancy Rate distribution (Rooms)
plt.figure(figsize=(12, 8))
sns.violinplot(x='PROGRAM_MODEL', y='OCCUPANCY_RATE_ROOMS', data=selected_data)
plt.title('Occupancy Rates Distribution by Program Model (Rooms)')
plt.xlabel('Program Model')
plt.ylabel('Occupancy Rate (Rooms)')
pdf_pages.savefig()
plt.show()

# Correlation Matrix for selected data
correlation_matrix = selected_data[['PROGRAM_MODEL', 'SERVICE_USER_COUNT', 'CAPACITY_ACTUAL_BED', 'OCCUPIED_BEDS','CAPACITY_ACTUAL_ROOM', 'OCCUPIED_ROOMS', 'OCCUPANCY_RATE_BEDS', 'OCCUPANCY_RATE_ROOMS' ]].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Heatmap')
pdf_pages.savefig()
plt.show()

# Barplot for Program Model count
plt.figure(figsize=(10, 6))
sns.countplot(x='PROGRAM_MODEL', data=selected_data)
plt.title('Counts of Program Models')
plt.xlabel('Program Model')
plt.ylabel('Count')
pdf_pages.savefig()
plt.show()

# Barplot for Sector count
plt.figure(figsize=(10, 6))
sns.countplot(x='SECTOR', data=df)
plt.title('Counts of Sector')
plt.xlabel('Sector Type')
plt.ylabel('Count')
pdf_pages.savefig()
plt.show()

# Close pdf file

pdf_pages.close()